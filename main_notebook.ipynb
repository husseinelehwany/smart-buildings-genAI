{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b2b1adf",
   "metadata": {},
   "source": [
    "# Gen AI LLMs\n",
    "This script demonstrates the use of LLMs for buildings operation <br>\n",
    "It demonestrates how to LLMs with Ollama opensource software <br>\n",
    "Prepared by: Hussein Elehwany <br>\n",
    "Created on: 19/12/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b872873",
   "metadata": {},
   "source": [
    "# Basic setup\n",
    "* Download Ollama: https://ollama.com/\n",
    "* Check if Ollama installed successfully: \n",
    "    * open cmd \n",
    "    * Execute command **ollama**\n",
    "* Download LLM: \n",
    "    * **ollama pull llama3**\n",
    "* Test model \n",
    "    * **ollama run llama3**\n",
    "* give the model some prompts\n",
    "* to exit: \n",
    "    * **/bye**\n",
    "* install packages: \n",
    "    * **pip install langchain**\n",
    "    * **pip install langchain-ollama**\n",
    "    * **pip install ollama**\n",
    "* Find Ollama git and available models here: https://github.com/ollama/ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f567f85",
   "metadata": {},
   "source": [
    "# Basic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a86dc937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import time\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# get LLM model\n",
    "model = OllamaLLM(model=\"llama3.2-vision\")  #llama3 llama3.2-vision  nous-hermes2 wizardlm2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85999e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "result = model.invoke(input=\"what is 1+1\")\n",
    "print(result)\n",
    "print(\"time= \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb6771a",
   "metadata": {},
   "source": [
    "wizardlm2: 8.45 17.64  6.24\n",
    "llama3: 12.87 2.89 2.705 2.71\n",
    "nous-hermes2: 23.05 5.13 29.15 6.0\n",
    "llama3.2: 16 1.8 1.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f5f3e8",
   "metadata": {},
   "source": [
    "create prompt, a template that will always be given to the LLM <br>\n",
    "connect the prompt to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b7773",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Answer the question below.\n",
    "Here is the conversation history: {context}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"context\": \"\", \"question\": \"how are you\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e5964",
   "metadata": {},
   "source": [
    "conversation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a01a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_conversation():\n",
    "    context = \"\"\n",
    "    print(\"Welcome to BPRC ChatBot! Type exit to quit.\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "        result = chain.invoke({\"context\": context, \"question\": user_input})\n",
    "        print(\"BPRC bot: \", result)\n",
    "        context +=f\"\\nUser: {user_input}\\nAI: {result}\"\n",
    "\n",
    "handle_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc9e929",
   "metadata": {},
   "source": [
    "# Building example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26280e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OllamaLLM(model=\"llama3.2-vision\")\n",
    "template = \"\"\"\n",
    "You are a building operator.\n",
    "You need to find out or calculate the total floor area of the building in square meters given this building description {question}.\n",
    "show steps and conclude with\n",
    "*the total floor area of in square meters: *\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "chain = prompt | model\n",
    "# show steps and conclude with\n",
    "# give answer in this sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb051267",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    user_input = \"the building is 12 storeys each 400 sqft\"\n",
    "    result = chain.invoke({\"question\": user_input})\n",
    "    print(\"BPRC bot: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2ff2f8",
   "metadata": {},
   "source": [
    "Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e3d562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OllamaLLM(model=\"llama3.2-vision\")\n",
    "template = \"\"\"\n",
    "You are a building operator.\n",
    "You need to find out or calculate the window to wall ratio of the building given this building description {question}.\n",
    "show steps and conclude with\n",
    "*the window to wall ratio WWR is: *\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "chain = prompt | model\n",
    "# show steps and conclude with\n",
    "# give answer in this sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6944219c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPRC bot:  To calculate the Window-to-Wall Ratio (WWR), I'll follow these steps:\n",
      "\n",
      "**Step 1: Calculate the total floor area**\n",
      "\n",
      "Building dimensions:\n",
      "Length (L) = 24 m\n",
      "Width (W) = 12 m\n",
      "Number of storeys = 10\n",
      "Height per storey = 3 m\n",
      "\n",
      "Total floor area = Number of storeys × Area per floor\n",
      "= 10 × (24 m × 12 m)\n",
      "= 2880 m²\n",
      "\n",
      "**Step 2: Calculate the total wall area**\n",
      "\n",
      "Since we don't have information about the wall thickness or any other obstacles, I'll assume the entire perimeter is usable for walls. The building has four sides:\n",
      "Length = 24 m\n",
      "Width = 12 m\n",
      "Perimeter (P) = 2 × (L + W)\n",
      "= 2 × (24 m + 12 m)\n",
      "= 72 m\n",
      "\n",
      "Since we have a rectangular shape, I'll calculate the area of each side separately and then sum them up:\n",
      "Area of longer sides (A1) = Length × Height\n",
      "= 24 m × 3 m\n",
      "= 72 m²\n",
      "Number of longer sides = 4\n",
      "Total area of longer sides = A1 × Number of longer sides\n",
      "= 72 m² × 4\n",
      "= 288 m²\n",
      "\n",
      "Area of shorter sides (A2) = Width × Height\n",
      "= 12 m × 3 m\n",
      "= 36 m²\n",
      "Number of shorter sides = 4\n",
      "Total area of shorter sides = A2 × Number of shorter sides\n",
      "= 36 m² × 4\n",
      "= 144 m²\n",
      "\n",
      "Total wall area = Total area of longer sides + Total area of shorter sides\n",
      "= 288 m² + 144 m²\n",
      "= 432 m²\n",
      "\n",
      "**Step 3: Calculate the total window area**\n",
      "\n",
      "Number of windows = 12\n",
      "Window dimensions (W × L) = 1.5 m × 2.75 m\n",
      "Area per window = W × L\n",
      "= 1.5 m × 2.75 m\n",
      "= 4.125 m²\n",
      "\n",
      "Total window area = Number of windows × Area per window\n",
      "= 12 × 4.125 m²\n",
      "= 49.5 m²\n",
      "\n",
      "**Step 4: Calculate the Window-to-Wall Ratio (WWR)**\n",
      "\n",
      "WWR is calculated by dividing the total window area by the total wall area:\n",
      "WWR = Total window area ÷ Total wall area\n",
      "= 49.5 m² ÷ 432 m²\n",
      "≈ 0.115 or 11.5%\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "*The Window-to-Wall Ratio WWR is: 11.5%\n"
     ]
    }
   ],
   "source": [
    "user_input = \"the building is 12m by 24 m and has 10 storeys each is 3m high, with total of 12 windows, each is 1.5 by 2.75m\"\n",
    "result = chain.invoke({\"question\": user_input})\n",
    "print(\"BPRC bot: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc78af2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
